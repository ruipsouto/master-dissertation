This dissertation addresses the viability of using machine learning in query optimization by proposing a middleware layer that can be used on top of a conventional relational database.

The solution is based on the client interface of the underlying database extending it with machine learning capabilities to select the best set of strategy settings on a per-query basis. The prototype was built around three different modules with distinct concerns that interact with one another to leverage machine learning techniques to improve optimizer settings recommendation quality with minimal changes to state-of-the-art database systems. Since it extends the \gls{dbms} interface and has minimal impact on the database clients, it can be further extended with new features to enhance query optimization even more.

The prototype implementation was built on top of PostgreSQL. It was tested using two different benchmarks to evaluate the benefits and the overall cost of adding machine learning guarantees to the underlying query optimizer. The results have shown us that, when using the \gls{tpch} benchmark, a read-intensive workload, the overall query runtime decreased by 3\%, while with \gls{job}, a real-world data set with an average of 8 joins per query the impact was as far as 19\%. In conclusion, the results have shown that integrating learned models represents a candidate way of comparing the execution cost of different plans and results in higher accuracy than using cost model estimates or keeping the optimizer strategy settings to their default values.

\section{Future Work}

One of the main goals for this dissertation was to create a middleware that would be applied to any relational database by leveraging readily available mechanisms in most database systems.

The prototype was implemented on top of PostgreSQL. However, it intended to test the solution on top of other state-of-the-art database systems. In short, a new research question would be to investigate whether the solution can obtain the same machine learning capabilities and results and evaluate if the cost of offering these capabilities stays in the same order of magnitude as the one achieved for PostgreSQL.

Finally, it would be interesting to note that the approach follows a static supervised machine learning approach, meaning that there is a clear separation between training and testing phases. Even though this document demonstrated the potential to apply learned techniques to optimization tuning, the lack of feedback means that, at the current form, the optimizer may still select the same bad plan repeatedly and never learn from its previous bad or good choices. As a more promising approach in real-world scenarios, future work intends to extend the current prototype to allow the training process to be done incrementally while a continuous stream of data is made available over time, as described earlier. This will allow to: (1) reduce the overhead of collecting execution data and generating a data set from it and (2) increase the adaptability to unknown scenarios by making it able to learn from past experiences.